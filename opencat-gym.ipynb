{"cells":[{"cell_type":"markdown","metadata":{"id":"_H3kIRihf3Ma"},"source":["# Mounting Drive\n","A data drive is mounted, from where the URDF-model will be loaded. It is also necessary to save training data."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24912,"status":"ok","timestamp":1706975681526,"user":{"displayName":"Gerold S.","userId":"08847029510990248057"},"user_tz":-60},"id":"nNWNZdhMQub2","outputId":"86afae1a-903a-4780-8fdf-c5df1fb0c4da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"8YhlWsZBgPOd"},"source":["# Install Python Packages\n","Now the python packages needed are installed. **Stable Baselines** provides the training agents and suits as a framework.\n","\n","**Pybullet** is the simulation environment. Into Pybullet the robot model URDF will be loaded and serves as a training environment."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42730,"status":"ok","timestamp":1706975724243,"user":{"displayName":"Gerold S.","userId":"08847029510990248057"},"user_tz":-60},"id":"xWaEe1mgZ2jv","outputId":"839b3d7c-3dcd-48ba-f18c-6bd748854e72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stable-baselines3[extra]\n","  Downloading stable_baselines3-2.2.1-py3-none-any.whl (181 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[extra])\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.23.5)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.1.0+cu121)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n","Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.0)\n","Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra])\n","  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n","Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n","  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n","Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.5.0)\n","Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra])\n","  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra])\n","  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.60.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.5.2)\n","Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.1.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=78af713c803fcc5dac872b7dbe6360bc7330ac0f4adba52fe3f64f00738afb31\n","  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: farama-notifications, gymnasium, ale-py, shimmy, AutoROM.accept-rom-license, autorom, stable-baselines3\n","Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 farama-notifications-0.0.4 gymnasium-0.29.1 shimmy-1.3.0 stable-baselines3-2.2.1\n","Collecting pybullet\n","  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybullet\n","Successfully installed pybullet-3.2.6\n"]}],"source":["!pip install \"stable-baselines3[extra]\"\n","!pip install pybullet\n","#!pip install sb3-contrib\n","#!pip install sbx-rl"]},{"cell_type":"markdown","metadata":{"id":"sIP1lDbihCGE"},"source":["# Gymnasium Training Environment\n","Here we describe the training environment as a **gymnasium** environment."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1706982719446,"user":{"displayName":"Gerold S.","userId":"08847029510990248057"},"user_tz":-60},"id":"doNTS_gKZVKk"},"outputs":[],"source":["import gymnasium as gym\n","import numpy as np\n","import pybullet as p\n","import pybullet_data\n","\n","\n","# Constants to define training and visualisation.\n","GUI_MODE = False          # Set \"True\" to display pybullet in a window\n","EPISODE_LENGTH = 250      # Number of steps for one training episode\n","MAXIMUM_LENGTH = 2e6      # Number of total steps for entire training\n","\n","# Factors to weight rewards and penalties.\n","PENALTY_STEPS = 2e6       # Increase of penalty by step_counter/PENALTY_STEPS\n","FAC_MOVEMENT = 1000.0     # Reward movement in x-direction\n","FAC_STABILITY = 0.1       # Punish body roll and pitch velocities\n","FAC_Z_VELOCITY = 0.0      # Punish z movement of body\n","FAC_SLIP = 0.0            # Punish slipping of paws\n","FAC_ARM_CONTACT = 0.01    # Punish crawling on arms and elbows\n","FAC_SMOOTH_1 = 1.0        # Punish jitter and vibrational movement, 1st order\n","FAC_SMOOTH_2 = 1.0        # Punish jitter and vibrational movement, 2nd order\n","FAC_CLEARANCE = 0.0       # Factor to enfore foot clearance to PAW_Z_TARGET\n","PAW_Z_TARGET = 0.005      # Target height (m) of paw during swing phase\n","\n","BOUND_ANGLE = 110         # Joint maximum angle (deg)\n","STEP_ANGLE = 11           # Maximum angle (deg) delta per step\n","ANG_FACTOR = 0.1          # Improve angular velocity resolution before clip.\n","\n","# Values for randomization, to improve sim to real transfer.\n","RANDOM_GYRO = 0           # Percent\n","RANDOM_joint_angs = 0      # Percent\n","RANDOM_MASS = 0           # Percent, currently inactive\n","RANDOM_FRICTION = 0       # Percent, currently inactive\n","\n","LENGTH_RECENT_ANGLES = 3  # Buffer to read recent joint angles\n","LENGTH_JOINT_HISTORY = 30 # Number of steps to store joint angles.\n","\n","# Size of oberservation space is set up of:\n","# [LENGTH_JOINT_HISTORY, quaternion, gyro]\n","SIZE_OBSERVATION = LENGTH_JOINT_HISTORY * 8 + 6\n","\n","\n","class OpenCatGymEnv(gym.Env):\n","    \"\"\" Gymnasium environment (stable baselines 3) for OpenCat robots.\n","    \"\"\"\n","\n","    metadata = {'render.modes': ['human']}\n","\n","    def __init__(self):\n","        self.step_counter = 0\n","        self.step_counter_session = 0\n","        self.state_history = np.array([])\n","        self.angle_history = np.array([])\n","        self.bound_ang = np.deg2rad(BOUND_ANGLE)\n","\n","        if GUI_MODE:\n","            p.connect(p.GUI)\n","            # Uncommend to create a video.\n","            #video_options = (\"--width=960 --height=540\n","            #                + \"--mp4=\\\"training.mp4\\\" --mp4fps=60\")\n","            #p.connect(p.GUI, options=video_options)\n","        else:\n","            # Use for training without visualisation (significantly faster).\n","            p.connect(p.DIRECT)\n","\n","        p.configureDebugVisualizer(p.COV_ENABLE_GUI, 0)\n","        p.resetDebugVisualizerCamera(cameraDistance=0.5,\n","                                     cameraYaw=-170,\n","                                     cameraPitch=-40,\n","                                     cameraTargetPosition=[0.4,0,0])\n","\n","        # The action space are the 8 joint angles.\n","        self.action_space = gym.spaces.Box(np.array([-1]*8), np.array([1]*8))\n","\n","        # The observation space are the torso roll, pitch and the\n","        # angular velocities and a history of the last 30 joint angles.\n","        self.observation_space = gym.spaces.Box(np.array([-1]*SIZE_OBSERVATION),\n","                                                np.array([1]*SIZE_OBSERVATION))\n","\n","\n","    def step(self, action):\n","        p.configureDebugVisualizer(p.COV_ENABLE_SINGLE_STEP_RENDERING)\n","        last_position = p.getBasePositionAndOrientation(self.robot_id)[0][0]\n","        joint_angs = np.asarray(p.getJointStates(self.robot_id, self.joint_id),\n","                                                   dtype=object)[:,0]\n","        ds = np.deg2rad(STEP_ANGLE) # Maximum change of angle per step\n","        joint_angs += action * ds # Change per step including agent action\n","\n","        # Apply joint boundaries individually.\n","        min_ang = -self.bound_ang\n","        max_ang = self.bound_ang\n","        joint_angs[0] = np.clip(joint_angs[0], min_ang, max_ang) # shoulder_left\n","        joint_angs[1] = np.clip(joint_angs[1], min_ang, max_ang) # elbow_left\n","        joint_angs[2] = np.clip(joint_angs[2], min_ang, max_ang) # shoulder_right\n","        joint_angs[3] = np.clip(joint_angs[3], min_ang, max_ang) # elbow_right\n","        joint_angs[4] = np.clip(joint_angs[4], min_ang, max_ang) # hip_right\n","        joint_angs[5] = np.clip(joint_angs[5], min_ang, max_ang) # knee_right\n","        joint_angs[6] = np.clip(joint_angs[6], min_ang, max_ang) # hip_left\n","        joint_angs[7] = np.clip(joint_angs[7], min_ang, max_ang) # knee_left\n","\n","        # Transform angle to degree and perform rounding, because\n","        # OpenCat robot have only integer values.\n","        joint_angsDeg = np.rad2deg(joint_angs.astype(np.float64))\n","        joint_angsDegRounded = joint_angsDeg.round()\n","        joint_angs = np.deg2rad(joint_angsDegRounded)\n","\n","        # Simulate delay for data transfer. Delay has to be modeled to close\n","        # \"reality gap\").\n","        p.stepSimulation()\n","\n","        # Check for friction of paws, to prevent slipping while training.\n","        paw_contact = []\n","        paw_idx = [3, 6, 9, 12]\n","        for idx in paw_idx:\n","            paw_contact.append(True if p.getContactPoints(bodyA=self.robot_id,\n","                                                          linkIndexA=idx)\n","                                    else False)\n","\n","        paw_slipping = 0\n","        for in_contact in np.nonzero(paw_contact)[0]:\n","            paw_slipping += np.linalg.norm((\n","                            p.getLinkState(self.robot_id,\n","                                           linkIndex=paw_idx[in_contact],\n","                                           computeLinkVelocity=1)[0][0:1]))\n","\n","        # Read clearance of paw from ground\n","        paw_clearance = 0\n","        for idx in paw_idx:\n","            paw_z_pos = p.getLinkState(self.robot_id, linkIndex=idx)[0][2]\n","            paw_clearance += (paw_z_pos-PAW_Z_TARGET)**2 * np.linalg.norm(\n","                (p.getLinkState(self.robot_id, linkIndex=idx,\n","                                computeLinkVelocity=1)[0][0:1]))**0.5\n","\n","        # Check if elbows or lower arm are in contact with ground\n","        arm_idx = [1, 2, 4, 5]\n","        for idx in arm_idx:\n","            if p.getContactPoints(bodyA=self.robot_id, linkIndexA=idx):\n","                self.arm_contact += 1\n","\n","        # Read clearance of torso from ground\n","        base_clearance = p.getBasePositionAndOrientation(self.robot_id)[0][2]\n","\n","        # Set new joint angles\n","        p.setJointMotorControlArray(self.robot_id,\n","                                    self.joint_id,\n","                                    p.POSITION_CONTROL,\n","                                    joint_angs,\n","                                    forces=np.ones(8)*0.2)\n","        p.stepSimulation() # Delay of data transfer\n","\n","        # Normalize joint_angs\n","        joint_angs[0] /= self.bound_ang\n","        joint_angs[1] /= self.bound_ang\n","        joint_angs[2] /= self.bound_ang\n","        joint_angs[3] /= self.bound_ang\n","        joint_angs[4] /= self.bound_ang\n","        joint_angs[5] /= self.bound_ang\n","        joint_angs[6] /= self.bound_ang\n","        joint_angs[7] /= self.bound_ang\n","\n","        # Adding every 2nd angle to the joint angle history.\n","        if(self.step_counter % 2 == 0):\n","            self.angle_history = np.append(self.angle_history,\n","                                           self.randomize(joint_angs,\n","                                                          RANDOM_joint_angs))\n","            self.angle_history = np.delete(self.angle_history, np.s_[0:8])\n","\n","        self.recent_angles = np.append(self.recent_angles, joint_angs)\n","        self.recent_angles = np.delete(self.recent_angles, np.s_[0:8])\n","\n","        joint_angs_prev = self.recent_angles[8:16]\n","        joint_angs_prev_prev = self.recent_angles[0:8]\n","\n","        # Read robot state (pitch, roll and their derivatives of the torso).\n","        state_pos, state_ang = p.getBasePositionAndOrientation(self.robot_id)\n","        p.stepSimulation() # Emulated delay of data transfer via serial port\n","        state_ang_euler = np.asarray(p.getEulerFromQuaternion(state_ang)[0:2])\n","        state_vel = np.asarray(p.getBaseVelocity(self.robot_id)[1])\n","        state_vel = state_vel[0:2]*ANG_FACTOR\n","        state_vel_clip = np.clip(state_vel, -1, 1)\n","        self.state_robot = np.concatenate((state_ang, state_vel_clip))\n","        current_position = p.getBasePositionAndOrientation(self.robot_id)[0][0]\n","\n","        # Penalty and reward\n","        smooth_movement = np.sum(\n","            FAC_SMOOTH_1*np.abs(joint_angs-joint_angs_prev)**2\n","            + FAC_SMOOTH_2*np.abs(joint_angs\n","            - 2*joint_angs_prev\n","            + joint_angs_prev_prev)**2)\n","\n","        z_velocity = p.getBaseVelocity(self.robot_id)[0][2]\n","\n","        body_stability = (FAC_STABILITY * (state_vel_clip[0]**2\n","                                          + state_vel_clip[1]**2)\n","                                          + FAC_Z_VELOCITY * z_velocity**2)\n","\n","        movement_forward = current_position - last_position\n","        reward = (FAC_MOVEMENT * movement_forward\n","                 - self.step_counter_session/PENALTY_STEPS * (\n","                    smooth_movement + body_stability\n","                    + FAC_CLEARANCE * paw_clearance\n","                    + FAC_SLIP * paw_slipping**2\n","                    + FAC_ARM_CONTACT * self.arm_contact))\n","\n","        # Set state of the current state.\n","        terminated = False\n","        truncated = False\n","        info = {}\n","\n","        # Stop criteria of current learning episode:\n","        # Number of steps or robot fell.\n","        self.step_counter += 1\n","        if self.step_counter > EPISODE_LENGTH:\n","            self.step_counter_session += self.step_counter\n","            terminated = False\n","            truncated = True\n","\n","        elif self.is_fallen(): # Robot fell\n","            self.step_counter_session += self.step_counter\n","            reward = 0\n","            terminated = True\n","            truncated = False\n","\n","        self.observation = np.hstack((self.state_robot, self.angle_history))\n","\n","        return (np.array(self.observation).astype(np.float32),\n","                        reward, terminated, truncated, info)\n","\n","\n","    def reset(self, seed=None, options=None):\n","        self.step_counter = 0\n","        self.arm_contact = 0\n","        p.resetSimulation()\n","        # Disable rendering during loading.\n","        p.configureDebugVisualizer(p.COV_ENABLE_RENDERING,0)\n","        p.setGravity(0,0,-9.81)\n","        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n","        plane_id = p.loadURDF(\"plane.urdf\")\n","\n","        start_pos = [0,0,0.08]\n","        start_orient = p.getQuaternionFromEuler([0,0,0])\n","\n","        urdf_path = \"/content/drive/My Drive/opencat-gym-esp32/models/\"\n","        self.robot_id = p.loadURDF(urdf_path + \"bittle_accurate.urdf\",\n","                                   start_pos, start_orient,\n","                                   flags=p.URDF_USE_SELF_COLLISION)\n","\n","        # Initialize urdf links and joints.\n","        self.joint_id = []\n","        #paramIds = []\n","        for j in range(p.getNumJoints(self.robot_id)):\n","            info = p.getJointInfo(self.robot_id, j)\n","            joint_name = info[1]\n","            joint_type = info[2]\n","\n","            if (joint_type == p.JOINT_PRISMATIC\n","                or joint_type == p.JOINT_REVOLUTE):\n","                self.joint_id.append(j)\n","                #paramIds.append(p.addUserDebugParameter(joint_name.decode(\"utf-8\")))\n","                # Limiting motor dynamics. Although bittle's dynamics seem to\n","                # be be quite high like up to 7 rad/s.\n","                p.changeDynamics(self.robot_id, j, maxJointVelocity = np.pi*10)\n","\n","        # Setting start position. This influences training.\n","        joint_angs = np.deg2rad(np.array([1, 0, 1, 0, 1, 0, 1, 0])*50)\n","\n","        i = 0\n","        for j in self.joint_id:\n","            p.resetJointState(self.robot_id,j, joint_angs[i])\n","            i = i+1\n","\n","        # Normalize joint angles.\n","        joint_angs[0] /= self.bound_ang\n","        joint_angs[1] /= self.bound_ang\n","        joint_angs[2] /= self.bound_ang\n","        joint_angs[3] /= self.bound_ang\n","        joint_angs[4] /= self.bound_ang\n","        joint_angs[5] /= self.bound_ang\n","        joint_angs[6] /= self.bound_ang\n","        joint_angs[7] /= self.bound_ang\n","\n","        # Read robot state (pitch, roll and their derivatives of the torso)\n","        state_ang = p.getBasePositionAndOrientation(self.robot_id)[1]\n","        state_vel = np.asarray(p.getBaseVelocity(self.robot_id)[1])\n","        state_vel = state_vel[0:2]*ANG_FACTOR\n","        self.state_robot = np.concatenate((state_ang,\n","                                           np.clip(state_vel, -1, 1)))\n","\n","        # Initialize robot state history with reset position\n","        state_joints = np.asarray(\n","            p.getJointStates(self.robot_id, self.joint_id), dtype=object)[:,0]\n","        state_joints /= self.bound_ang\n","\n","        self.angle_history = np.tile(state_joints, LENGTH_JOINT_HISTORY)\n","        self.recent_angles = np.tile(state_joints, LENGTH_RECENT_ANGLES)\n","        self.observation = np.concatenate((self.state_robot,\n","                                           self.angle_history))\n","        p.configureDebugVisualizer(p.COV_ENABLE_RENDERING,1)\n","        info = {}\n","        return np.array(self.observation).astype(np.float32), info\n","\n","\n","    def render(self, mode='human'):\n","        pass\n","\n","\n","    def close(self):\n","        p.disconnect()\n","\n","\n","    def is_fallen(self):\n","        \"\"\" Check if robot is fallen. It becomes \"True\",\n","            when pitch or roll is more than 1.3 rad.\n","        \"\"\"\n","        pos, orient = p.getBasePositionAndOrientation(self.robot_id)\n","        orient = p.getEulerFromQuaternion(orient)\n","        is_fallen = (np.fabs(orient[0]) > 1.3\n","                    or np.fabs(orient[1]) > 1.3)\n","\n","        return is_fallen\n","\n","\n","    def randomize(self, value, percentage):\n","        \"\"\" Randomize value within percentage boundaries.\n","        \"\"\"\n","        percentage /= 100\n","        value_randomized = value * (1 + percentage*(2*np.random.rand()-1))\n","\n","        return value_randomized"]},{"cell_type":"markdown","metadata":{"id":"h3SFtFMLhSL8"},"source":["#Starting Training\n","This is the main function to start training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52AQWfpRZak9","outputId":"924ddd43-4156-43a8-ebe9-36c4e1b42a40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 251      |\n","|    ep_rew_mean     | 53.9     |\n","| time/              |          |\n","|    fps             | 473      |\n","|    iterations      | 1        |\n","|    time_elapsed    | 34       |\n","|    total_timesteps | 16384    |\n","---------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 58.4        |\n","| time/                   |             |\n","|    fps                  | 375         |\n","|    iterations           | 2           |\n","|    time_elapsed         | 87          |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.013047082 |\n","|    clip_fraction        | 0.174       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.3       |\n","|    explained_variance   | 0.00182     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 17.6        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.013      |\n","|    std                  | 1           |\n","|    value_loss           | 39.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 53.5        |\n","| time/                   |             |\n","|    fps                  | 351         |\n","|    iterations           | 3           |\n","|    time_elapsed         | 139         |\n","|    total_timesteps      | 49152       |\n","| train/                  |             |\n","|    approx_kl            | 0.016366817 |\n","|    clip_fraction        | 0.213       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.4       |\n","|    explained_variance   | 0.42        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 7.17        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0131     |\n","|    std                  | 1           |\n","|    value_loss           | 31.2        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 251        |\n","|    ep_rew_mean          | 40.9       |\n","| time/                   |            |\n","|    fps                  | 337        |\n","|    iterations           | 4          |\n","|    time_elapsed         | 193        |\n","|    total_timesteps      | 65536      |\n","| train/                  |            |\n","|    approx_kl            | 0.01682869 |\n","|    clip_fraction        | 0.203      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -11.3      |\n","|    explained_variance   | 0.703      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 10.5       |\n","|    n_updates            | 30         |\n","|    policy_gradient_loss | -0.00663   |\n","|    std                  | 0.999      |\n","|    value_loss           | 20.8       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 52.7        |\n","| time/                   |             |\n","|    fps                  | 330         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 247         |\n","|    total_timesteps      | 81920       |\n","| train/                  |             |\n","|    approx_kl            | 0.017201867 |\n","|    clip_fraction        | 0.226       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.3       |\n","|    explained_variance   | 0.834       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 4.53        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.00678    |\n","|    std                  | 0.993       |\n","|    value_loss           | 16.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 62.7        |\n","| time/                   |             |\n","|    fps                  | 327         |\n","|    iterations           | 6           |\n","|    time_elapsed         | 300         |\n","|    total_timesteps      | 98304       |\n","| train/                  |             |\n","|    approx_kl            | 0.018093238 |\n","|    clip_fraction        | 0.248       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.3       |\n","|    explained_variance   | 0.88        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 5.95        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.00542    |\n","|    std                  | 0.991       |\n","|    value_loss           | 15.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 92.3        |\n","| time/                   |             |\n","|    fps                  | 323         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 353         |\n","|    total_timesteps      | 114688      |\n","| train/                  |             |\n","|    approx_kl            | 0.021947037 |\n","|    clip_fraction        | 0.245       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.3       |\n","|    explained_variance   | 0.882       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 6           |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.00734    |\n","|    std                  | 0.988       |\n","|    value_loss           | 15.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 108         |\n","| time/                   |             |\n","|    fps                  | 321         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 407         |\n","|    total_timesteps      | 131072      |\n","| train/                  |             |\n","|    approx_kl            | 0.021987066 |\n","|    clip_fraction        | 0.259       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.2       |\n","|    explained_variance   | 0.868       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 10.9        |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.00796    |\n","|    std                  | 0.984       |\n","|    value_loss           | 17.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 137         |\n","| time/                   |             |\n","|    fps                  | 318         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 462         |\n","|    total_timesteps      | 147456      |\n","| train/                  |             |\n","|    approx_kl            | 0.019727908 |\n","|    clip_fraction        | 0.255       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.2       |\n","|    explained_variance   | 0.87        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 6.44        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.00767    |\n","|    std                  | 0.982       |\n","|    value_loss           | 16.2        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 251        |\n","|    ep_rew_mean          | 152        |\n","| time/                   |            |\n","|    fps                  | 317        |\n","|    iterations           | 10         |\n","|    time_elapsed         | 516        |\n","|    total_timesteps      | 163840     |\n","| train/                  |            |\n","|    approx_kl            | 0.02040105 |\n","|    clip_fraction        | 0.271      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -11.2      |\n","|    explained_variance   | 0.854      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 4.92       |\n","|    n_updates            | 90         |\n","|    policy_gradient_loss | -0.00726   |\n","|    std                  | 0.981      |\n","|    value_loss           | 15.3       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 149         |\n","| time/                   |             |\n","|    fps                  | 316         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 569         |\n","|    total_timesteps      | 180224      |\n","| train/                  |             |\n","|    approx_kl            | 0.022373527 |\n","|    clip_fraction        | 0.281       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.2       |\n","|    explained_variance   | 0.91        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 3.6         |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.00812    |\n","|    std                  | 0.98        |\n","|    value_loss           | 13          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 164         |\n","| time/                   |             |\n","|    fps                  | 314         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 624         |\n","|    total_timesteps      | 196608      |\n","| train/                  |             |\n","|    approx_kl            | 0.021970881 |\n","|    clip_fraction        | 0.269       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.2       |\n","|    explained_variance   | 0.914       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 4.33        |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.00524    |\n","|    std                  | 0.978       |\n","|    value_loss           | 13.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 250         |\n","|    ep_rew_mean          | 169         |\n","| time/                   |             |\n","|    fps                  | 312         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 680         |\n","|    total_timesteps      | 212992      |\n","| train/                  |             |\n","|    approx_kl            | 0.024505295 |\n","|    clip_fraction        | 0.286       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.2       |\n","|    explained_variance   | 0.901       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 3.17        |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.00531    |\n","|    std                  | 0.977       |\n","|    value_loss           | 13          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 173         |\n","| time/                   |             |\n","|    fps                  | 312         |\n","|    iterations           | 14          |\n","|    time_elapsed         | 734         |\n","|    total_timesteps      | 229376      |\n","| train/                  |             |\n","|    approx_kl            | 0.023272885 |\n","|    clip_fraction        | 0.277       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.928       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 6.6         |\n","|    n_updates            | 130         |\n","|    policy_gradient_loss | -0.00559    |\n","|    std                  | 0.975       |\n","|    value_loss           | 12.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 191         |\n","| time/                   |             |\n","|    fps                  | 312         |\n","|    iterations           | 15          |\n","|    time_elapsed         | 787         |\n","|    total_timesteps      | 245760      |\n","| train/                  |             |\n","|    approx_kl            | 0.023638882 |\n","|    clip_fraction        | 0.281       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.918       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 5.23        |\n","|    n_updates            | 140         |\n","|    policy_gradient_loss | -0.00891    |\n","|    std                  | 0.973       |\n","|    value_loss           | 16.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 250         |\n","|    ep_rew_mean          | 212         |\n","| time/                   |             |\n","|    fps                  | 311         |\n","|    iterations           | 16          |\n","|    time_elapsed         | 841         |\n","|    total_timesteps      | 262144      |\n","| train/                  |             |\n","|    approx_kl            | 0.025419228 |\n","|    clip_fraction        | 0.302       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.919       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 2.55        |\n","|    n_updates            | 150         |\n","|    policy_gradient_loss | -0.00533    |\n","|    std                  | 0.972       |\n","|    value_loss           | 13.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 216         |\n","| time/                   |             |\n","|    fps                  | 311         |\n","|    iterations           | 17          |\n","|    time_elapsed         | 895         |\n","|    total_timesteps      | 278528      |\n","| train/                  |             |\n","|    approx_kl            | 0.023307586 |\n","|    clip_fraction        | 0.282       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.89        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 2.88        |\n","|    n_updates            | 160         |\n","|    policy_gradient_loss | -0.00467    |\n","|    std                  | 0.971       |\n","|    value_loss           | 14.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 250         |\n","|    ep_rew_mean          | 217         |\n","| time/                   |             |\n","|    fps                  | 310         |\n","|    iterations           | 18          |\n","|    time_elapsed         | 948         |\n","|    total_timesteps      | 294912      |\n","| train/                  |             |\n","|    approx_kl            | 0.028673923 |\n","|    clip_fraction        | 0.299       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.851       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 5.6         |\n","|    n_updates            | 170         |\n","|    policy_gradient_loss | -0.00565    |\n","|    std                  | 0.969       |\n","|    value_loss           | 16          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 250         |\n","|    ep_rew_mean          | 223         |\n","| time/                   |             |\n","|    fps                  | 310         |\n","|    iterations           | 19          |\n","|    time_elapsed         | 1002        |\n","|    total_timesteps      | 311296      |\n","| train/                  |             |\n","|    approx_kl            | 0.022292813 |\n","|    clip_fraction        | 0.299       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.847       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 5.36        |\n","|    n_updates            | 180         |\n","|    policy_gradient_loss | -0.00212    |\n","|    std                  | 0.971       |\n","|    value_loss           | 16          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 221         |\n","| time/                   |             |\n","|    fps                  | 310         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 1055        |\n","|    total_timesteps      | 327680      |\n","| train/                  |             |\n","|    approx_kl            | 0.024756936 |\n","|    clip_fraction        | 0.295       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.862       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 5.44        |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.00633    |\n","|    std                  | 0.97        |\n","|    value_loss           | 15.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 233         |\n","| time/                   |             |\n","|    fps                  | 309         |\n","|    iterations           | 21          |\n","|    time_elapsed         | 1110        |\n","|    total_timesteps      | 344064      |\n","| train/                  |             |\n","|    approx_kl            | 0.027167711 |\n","|    clip_fraction        | 0.297       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.872       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 6.97        |\n","|    n_updates            | 200         |\n","|    policy_gradient_loss | -0.00172    |\n","|    std                  | 0.972       |\n","|    value_loss           | 19.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 241         |\n","| time/                   |             |\n","|    fps                  | 309         |\n","|    iterations           | 22          |\n","|    time_elapsed         | 1166        |\n","|    total_timesteps      | 360448      |\n","| train/                  |             |\n","|    approx_kl            | 0.024955668 |\n","|    clip_fraction        | 0.294       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.881       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 6.41        |\n","|    n_updates            | 210         |\n","|    policy_gradient_loss | -0.00418    |\n","|    std                  | 0.975       |\n","|    value_loss           | 19.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 251         |\n","|    ep_rew_mean          | 252         |\n","| time/                   |             |\n","|    fps                  | 308         |\n","|    iterations           | 23          |\n","|    time_elapsed         | 1220        |\n","|    total_timesteps      | 376832      |\n","| train/                  |             |\n","|    approx_kl            | 0.023515914 |\n","|    clip_fraction        | 0.314       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -11.1       |\n","|    explained_variance   | 0.871       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 4.37        |\n","|    n_updates            | 220         |\n","|    policy_gradient_loss | -0.00368    |\n","|    std                  | 0.974       |\n","|    value_loss           | 16.1        |\n","-----------------------------------------\n"]}],"source":["from stable_baselines3 import PPO\n","from stable_baselines3.common.env_checker import check_env\n","from stable_baselines3.common.env_util import make_vec_env\n","from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n","\n","# Create OpenCatGym environment from class and check if structure is correct\n","env = OpenCatGymEnv()\n","check_env(env)\n","\n","if __name__ == \"__main__\":\n","    # Set up number of parallel environments\n","    parallel_envs = 8\n","    envs = make_vec_env(OpenCatGymEnv, n_envs=parallel_envs, vec_env_cls=SubprocVecEnv) # only for PPO\n","\n","    # Change architecture of neural network to two hidden layers of size 256\n","    custom_arch = dict(net_arch=[256, 256])\n","\n","    # Define PPO agent and train\n","    model = PPO('MlpPolicy', envs,\n","                seed=42,\n","                policy_kwargs=custom_arch,\n","                n_steps=int(2048*8/parallel_envs),\n","                verbose=1).learn(MAXIMUM_LENGTH)\n","\n","    model.save(\"/content/drive/My Drive/opencat-gym-esp32/trained/opencat_gym_release_var3_seed_1p0_jitter_2e6\")\n","\n","    # Load model to continue previous training\n","    #model = PPO.load(\"/content/drive/My Drive/opencat-gym-esp32/trained/ppo_8_env_0p5_penalty_gradient_1p0_smooth_0p1_body_0p01_contact_arch_256_256_250steps_2e6\", env, policy_kwargs=custom_policy_kwargs, n_steps=int(2048*8/parallel_env), verbose=1, tensorboard_log=\"/content/drive/My Drive/opencat-gym-esp32/trained/tensorboard_logs/\").learn(2e6)\n","    #model.save(\"/content/drive/My Drive/opencat-gym-esp32/trained/ppo_8_env_0p5_penalty_gradient_1p0_smooth_0p1_body_0p01_contact_arch_256_256_250steps_4e6\")\n","\n","\n"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyNbltI9LB7U1mdDpYBHOhHl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}